{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbbc3d5f-bbbf-4a13-b2e0-58df143f2432",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizer import TokenizerWrapper, download_and_merge_text_files, train_tokenizer,download_file_from_url\n",
    "from dataset_loader import TextDataset, collate_fn\n",
    "from gru_model import GRULanguageModel\n",
    "from train_utils import train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad6c615a-72b9-462b-8868-36ff8f757892",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define model-specific hyperparameter grids\n",
    "hyperparams_grid = {\n",
    "    \"gru\": [\n",
    "        {\"embed_dim\": 128, \"hidden_dim\": 256, \"num_layers\": 2, \"lr\": 1e-3},\n",
    "        {\"embed_dim\": 256, \"hidden_dim\": 512, \"num_layers\": 3, \"lr\": 5e-4}\n",
    "    ],\n",
    "    \"lstm\": [\n",
    "        {\"embed_dim\": 128, \"hidden_dim\": 256, \"num_layers\": 2, \"lr\": 1e-3},\n",
    "        {\"embed_dim\": 256, \"hidden_dim\": 512, \"num_layers\": 3, \"lr\": 1e-4}\n",
    "    ],\n",
    "    \"rnn\": [\n",
    "        {\"embed_dim\": 128, \"hidden_dim\": 128, \"num_layers\": 2, \"lr\": 1e-3}\n",
    "    ],\n",
    "    \"transformer\": [\n",
    "        {\"embed_dim\": 256, \"num_heads\": 4, \"num_layers\": 2, \"lr\": 1e-3},\n",
    "        {\"embed_dim\": 512, \"num_heads\": 8, \"num_layers\": 4, \"lr\": 5e-4}\n",
    "    ]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "278f1595-0bb6-4bd8-8cfa-f16a498a5f42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from train_utils import train_model, evaluate_model\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "results = []\n",
    "\n",
    "def run_experiments(model_type, ModelClass, grid, tokenizer, train_loader, test_loader, device):\n",
    "    for idx, config in enumerate(grid):\n",
    "        model_id = f\"{model_type}_{idx}_{int(time.time())}\"\n",
    "        print(f\"\\n Training {model_id} with config: {config}\")\n",
    "        \n",
    "        if model_type == \"transformer\":\n",
    "            model = ModelClass(\n",
    "                vocab_size=VOCAB_SIZE,\n",
    "                embed_dim=config[\"embed_dim\"],\n",
    "                num_heads=config[\"num_heads\"],\n",
    "                num_layers=config[\"num_layers\"],\n",
    "                pad_token_id=tokenizer.get_pad_id()\n",
    "            ).to(device)\n",
    "        else:\n",
    "            model = ModelClass(\n",
    "                vocab_size=VOCAB_SIZE,\n",
    "                embed_dim=config[\"embed_dim\"],\n",
    "                hidden_dim=config[\"hidden_dim\"],\n",
    "                num_layers=config[\"num_layers\"],\n",
    "                pad_token_id=tokenizer.get_pad_id()\n",
    "            ).to(device)\n",
    "        \n",
    "        save_path = f\"{model_id}.pt\"\n",
    "        train_model(model, train_loader, test_loader, tokenizer, device, save_path, lr=config[\"lr\"], epochs=50)\n",
    "\n",
    "        ppl, bleu = evaluate_model(model, save_path, test_loader, tokenizer, device)\n",
    "        results.append({\n",
    "            \"model_type\": model_type,\n",
    "            \"config\": config,\n",
    "            \"perplexity\": ppl,\n",
    "            \"bleu_score\": bleu,\n",
    "            \"model_path\": save_path\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e320a523-aee6-4e45-a42b-39c4bec771c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "CORPUS_FILE = \"corpus.txt\"\n",
    "TRAIN_FILE = \"train.jsonl\"\n",
    "TEST_FILE = \"test.jsonl\"\n",
    "TOKENIZER_PREFIX = \"bpe_tokenizer\"\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Select Model Here ===\n",
    "#MODEL_TYPE = \"transformer\"  # Options: 'gru', 'lstm', 'rnn', 'transformer'\n",
    "#MODEL_SAVE_PATH = f\"best_{MODEL_TYPE}_model.pt\"\n",
    "\n",
    "# --- Step 1: Download data & train tokenizer ---\n",
    "#download_file_from_url(TRAIN_URL, TRAIN_FILE)\n",
    "#download_file_from_url(TEST_URL, TEST_FILE)\n",
    "#download_and_merge_text_files(DATA_URL, CORPUS_FILE)\n",
    "train_tokenizer(CORPUS_FILE, TOKENIZER_PREFIX, vocab_size=VOCAB_SIZE)\n",
    "tokenizer = TokenizerWrapper(f\"{TOKENIZER_PREFIX}.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60e814e0-f8a0-49eb-899e-45b5ade97b1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(TRAIN_FILE, tokenizer, MAX_SEQ_LEN)\n",
    "test_dataset = TextDataset(TEST_FILE, tokenizer, MAX_SEQ_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda b: collate_fn(b, tokenizer.get_pad_id()))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda b: collate_fn(b, tokenizer.get_pad_id()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "01f0046b-1a7e-4433-81b5-92e3db95a602",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gru_model import GRULanguageModel\n",
    "from lstm_model import LSTMLanguageModel\n",
    "from rnn_model import RNNLanguageModel\n",
    "from transformer_model import TransformerLanguageModel\n",
    "\n",
    "run_experiments(\"gru\", GRULanguageModel, hyperparams_grid[\"gru\"], tokenizer, train_loader, test_loader, DEVICE)\n",
    "run_experiments(\"lstm\", LSTMLanguageModel, hyperparams_grid[\"lstm\"], tokenizer, train_loader, test_loader, DEVICE)\n",
    "run_experiments(\"rnn\", RNNLanguageModel, hyperparams_grid[\"rnn\"], tokenizer, train_loader, test_loader, DEVICE)\n",
    "run_experiments(\"transformer\", TransformerLanguageModel, hyperparams_grid[\"transformer\"], tokenizer, train_loader, test_loader, DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a927eb39-d666-435f-a3da-1d31519f46fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(\"experiment_results.csv\", index=False)\n",
    "results_df.sort_values(by=\"perplexity\").head()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "llm_project_experiments",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "[System Module] Python 3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
