{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbbc3d5f-bbbf-4a13-b2e0-58df143f2432",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tokenizer import TokenizerWrapper, download_and_merge_text_files, train_tokenizer,download_file_from_url\n",
    "from dataset_loader import TextDataset, collate_fn\n",
    "from gru_model import GRULanguageModel\n",
    "from train_utils import train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "599da53b-6247-4c77-a374-1f8ddf581500",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# main.py\n",
    "\n",
    "import torch\n",
    "from tokenizer import TokenizerWrapper, download_and_merge_text_files, train_tokenizer, download_file_from_url\n",
    "from dataset_loader import TextDataset, collate_fn\n",
    "from train_utils import train_model, evaluate_model\n",
    "\n",
    "# Import all models\n",
    "from gru_model import GRULanguageModel\n",
    "from lstm_model import LSTMLanguageModel\n",
    "from rnn_model import RNNLanguageModel\n",
    "from transformer_model import TransformerLanguageModel\n",
    "\n",
    "# --- Config ---\n",
    "DATA_URL = \"https://api.github.com/repos/jghawaly/CSC7809_FoundationModels/contents/Project2/data/raw\"\n",
    "\n",
    "\n",
    "TRAIN_URL=\"https://raw.githubusercontent.com/jghawaly/CSC7809_FoundationModels/main/Project2/data/train.jsonl\"\n",
    "\n",
    "TEST_URL=\"https://raw.githubusercontent.com/jghawaly/CSC7809_FoundationModels/main/Project2/data/test.jsonl\"\n",
    "\n",
    "\n",
    "CORPUS_FILE = \"corpus.txt\"\n",
    "TRAIN_FILE = \"train.jsonl\"\n",
    "TEST_FILE = \"test.jsonl\"\n",
    "TOKENIZER_PREFIX = \"bpe_tokenizer\"\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_SEQ_LEN = 128\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# === Select Model Here ===\n",
    "MODEL_TYPE = \"transformer\"  # Options: 'gru', 'lstm', 'rnn', 'transformer'\n",
    "MODEL_SAVE_PATH = f\"best_{MODEL_TYPE}_model.pt\"\n",
    "\n",
    "# --- Step 1: Download data & train tokenizer ---\n",
    "download_file_from_url(TRAIN_URL, TRAIN_FILE)\n",
    "download_file_from_url(TEST_URL, TEST_FILE)\n",
    "download_and_merge_text_files(DATA_URL, CORPUS_FILE)\n",
    "train_tokenizer(CORPUS_FILE, TOKENIZER_PREFIX, vocab_size=VOCAB_SIZE)\n",
    "tokenizer = TokenizerWrapper(f\"{TOKENIZER_PREFIX}.model\")\n",
    "\n",
    "# --- Step 2: Dataset ---\n",
    "train_dataset = TextDataset(TRAIN_FILE, tokenizer, MAX_SEQ_LEN)\n",
    "test_dataset = TextDataset(TEST_FILE, tokenizer, MAX_SEQ_LEN)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=lambda b: collate_fn(b, tokenizer.get_pad_id()))\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=lambda b: collate_fn(b, tokenizer.get_pad_id()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f795d158-298b-4005-883b-135a27974869",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 3: Model Factory ---\n",
    "def build_model(model_type):\n",
    "    if model_type == \"gru\":\n",
    "        return GRULanguageModel(VOCAB_SIZE, 256, 512, 2, tokenizer.get_pad_id()).to(DEVICE)\n",
    "    elif model_type == \"lstm\":\n",
    "        return LSTMLanguageModel(VOCAB_SIZE, 256, 512, 2, tokenizer.get_pad_id()).to(DEVICE)\n",
    "    elif model_type == \"rnn\":\n",
    "        return RNNLanguageModel(VOCAB_SIZE, 256, 512, 2, tokenizer.get_pad_id()).to(DEVICE)\n",
    "    elif model_type == \"transformer\":\n",
    "        return TransformerLanguageModel(\n",
    "            vocab_size=VOCAB_SIZE,\n",
    "            embed_dim=256,\n",
    "            num_heads=4,\n",
    "            num_layers=4,\n",
    "            pad_token_id=tokenizer.get_pad_id()\n",
    "        ).to(DEVICE)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model type: {model_type}\")\n",
    "\n",
    "model = build_model(MODEL_TYPE)\n",
    "\n",
    "# --- Step 4: Train & Evaluate ---\n",
    "train_model(model, train_loader, test_loader, tokenizer, DEVICE, MODEL_SAVE_PATH, lr=1e-3, epochs=EPOCHS)\n",
    "evaluate_model(model, MODEL_SAVE_PATH, test_loader, tokenizer, DEVICE)\n",
    "\n",
    "# --- Step 5: Sample Generation ---\n",
    "custom_prompts = [\n",
    "    \"The spaceship landed on the surface of Mars and\",\n",
    "    \"He walked into the room, completely unaware that\",\n",
    "    \"Long ago in a forgotten village, a child was born who\",\n",
    "    \"Artificial intelligence will change the world when\",\n",
    "    \"What do you prefer â€” cat or dog?\"\n",
    "]\n",
    "\n",
    "print(f\"\\n--- Generations using {MODEL_TYPE.upper()} ---\")\n",
    "for prompt in custom_prompts:\n",
    "    output = model.generate(tokenizer, prompt, device=DEVICE, return_continuation_only=True)\n",
    "    print(f\" Prompt    : {prompt}\")\n",
    "    print(f\" Generated : {output}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "llm_project",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "[System Module] Python 3.11.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
